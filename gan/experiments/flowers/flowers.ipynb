{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from lib.utils import model ,preproc, newBuild, newGan\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment on flower paintings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 15:59:06.510486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:59:06.515823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:59:06.516171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:59:06.541143: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-26 15:59:06.541616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:59:06.541953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:59:06.542258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:59:06.891828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:59:06.892172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:59:06.892475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-26 15:59:06.892768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4074 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:0a:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "res = 128\n",
    "channel = 3\n",
    "# Preprocessing data with custom function\n",
    "batch_size = 4\n",
    "img_shape = (res,res,channel)\n",
    "epochs = 2000\n",
    "latent_dim = 128\n",
    "n_images = 16\n",
    "image_dir = \"../../oDig/flowers/\"\n",
    "checkpoint_dir = \"../../checkpoints/flower_check/\"\n",
    "#data_loc = \"../../datasets/celeb/\"\n",
    "image_freq = 200\n",
    "s = tf.random.normal([n_images, latent_dim]),\n",
    "checkpoint_freq = 200"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 969 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function=preproc.tanh_preprocess,\n",
    "                             horizontal_flip=True,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1,\n",
    "                             rotation_range=5,\n",
    "                             fill_mode='nearest'\n",
    "                             )\n",
    "train_dir = '/home/sandor/Dev/final/finalproject/gan/datasets/flowers'\n",
    "\n",
    "dataset = datagen.flow_from_directory(\n",
    "     train_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "constants = dict(\n",
    "    num_conv_layers = 4,\n",
    "    img_shape = img_shape,\n",
    "    dim = 8,\n",
    "    output = channel,\n",
    "    latent_dim = latent_dim,\n",
    "    kernel = 4,\n",
    "    stride = 2\n",
    ")\n",
    "callback = dict(\n",
    "    num_img = n_images,\n",
    "    cFreq = checkpoint_freq,\n",
    "    iFreq = image_freq,\n",
    "    seed = s,\n",
    "    loc = image_dir\n",
    ")\n",
    "gan_attributes = dict(\n",
    "    check_location= checkpoint_dir,\n",
    "    b_size=  batch_size,\n",
    "    l_dim= latent_dim,\n",
    "    data = dataset,\n",
    "    epochs=epochs,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8192)              1056768   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 8192)             32768     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 8192)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 16, 16, 128)      262272    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 16, 128)      512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 128)      262272    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 128)      262272    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64, 64, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 128, 128, 128)    262272    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128, 128, 128)    512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 128, 128, 128)     0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 128, 128, 3)      6147      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,146,819\n",
      "Trainable params: 2,129,411\n",
      "Non-trainable params: 17,408\n",
      "_________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 64)        3136      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 64, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        65600     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 64)        65600     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 16385     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151,489\n",
      "Trainable params: 151,105\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Checkpoint restored\n"
     ]
    }
   ],
   "source": [
    "name = 'Model_1-Same-Tanh-Batch-mDrop'\n",
    "parameters = dict(\n",
    "    model_name=name,\n",
    "    filter_mode=3,\n",
    "    gen_filter=7,\n",
    "    disc_filter=6,\n",
    "    is_batchnorm=True,\n",
    "    is_multi_drop=True,\n",
    "    is_tanh=True\n",
    ")\n",
    "model1 = model.ModelSettings(**constants, **parameters)\n",
    "gan1 = newBuild.GANBuilder(atrib=model1, name=name, **gan_attributes)\n",
    "g = newBuild.make_gan(gan1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Image transformations require SciPy. Install SciPy.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mnewGan\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mGANCallback\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras_preprocessing/image/affine_transformations.py:281\u001B[0m, in \u001B[0;36mapply_affine_transform\u001B[0;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001B[0m\n\u001B[1;32m    257\u001B[0m \u001B[38;5;124;03m\"\"\"Applies an affine transformation specified by the parameters given.\u001B[39;00m\n\u001B[1;32m    258\u001B[0m \n\u001B[1;32m    259\u001B[0m \u001B[38;5;124;03m# Arguments\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;124;03m    The transformed version of the input.\u001B[39;00m\n\u001B[1;32m    279\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m scipy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 281\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mImage transformations require SciPy. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    282\u001B[0m                       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInstall SciPy.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    283\u001B[0m transform_matrix \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m theta \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\u001B[0;31mImportError\u001B[0m: Image transformations require SciPy. Install SciPy."
     ]
    }
   ],
   "source": [
    "g.fit(dataset, epochs=epochs, callbacks = [newGan.GANCallback(name= name,**callback)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}